{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Summarizer</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressources <br>\n",
    "Unicode : https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Pkgs\n",
    "import spacy \n",
    "import re\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "# Pkgs for Normalizing Text\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "# Import Heapq for Finding the Top N Sentences\n",
    "from heapq import nlargest\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('french')\n",
    "\n",
    "def summarizer_perso (path,encoding):\n",
    "    raw_docx = open(path,'r',encoding=encoding)\n",
    "    raw_docx = raw_docx.read().strip()\n",
    "    import re\n",
    "    raw_docx = re.sub('\\n+',' ',raw_docx)#delete line break\n",
    "    docx = nlp(raw_docx)\n",
    "    # Build Word Frequency # word.text is tokenization in spacy\n",
    "    word_frequencies = {}  \n",
    "    for word in docx:\n",
    "        if word.text not in stop_words:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    # Sentence Tokens\n",
    "    sentence_list = [ sentence for sentence in docx.sents ]\n",
    "\n",
    "    # Sentence Scores\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "\n",
    "    summarized_sentences = nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    final_sentences = [ w.text for w in summarized_sentences ]\n",
    "    summary = ' '.join(final_sentences)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Partout, les eaux avaient monté, les rivières enflées, on consolidait les digues, on en bâtissait d'autres, plus hautes, mais qui se révélaient de nouveau insuffisantes. Le phénomène, inexplicable, échappait à toute logique, à toute prévision, à tout modèle, à toute saison.   Sur le port, les réfugiés se battent pour prendre place dans les derniers bateaux, pris de panique, convaincus qu'il s’agit là du dernier espoir de s'en sortir.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_perso('resume_pluies.txt','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Des recettes, des anecdotes, des histoires, des cartes, des gestes, des techniques, des ustensiles, des ingrédients… En un coup d’œil, toutes les réponses aux questions que l'on se pose ! Un livre entièrement illustré pour tout savoir sur la cuisine japonaise !\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_perso('resume_cuisine-jap.txt','utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Amour, science-fiction, polar, témoignage, aventure : tous les genres sont explorés par ces jeunes avec brio, révélant ainsi leur intérêt et leur talent pour l'écriture. Ces textes surprennent par leur fraîcheur, leur originalité, leur sincérité, et forment un kaléidoscope de l'imaginaire adolescent. Ce prix a été créé en mémoire de Clara, décédée subitement à l’âge de 13 ans des suites d’une malformation cardiaque.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_perso('resume_prix_clara.txt','utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumy function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "def summarizer_sumy (path,encoding):\n",
    "\tdocx = open(path,'r',encoding=encoding)\n",
    "\tdocx = docx.read()\n",
    "\tparser = PlaintextParser.from_string(docx,Tokenizer(\"french\"))\n",
    "\tlex_summarizer = LexRankSummarizer()\n",
    "\tsummary = lex_summarizer(parser.document,3)\n",
    "\tsummary_list = [str(sentence) for sentence in summary]\n",
    "\tresult = ' '.join(summary_list)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffUn livre entièrement illustré pour tout savoir sur la cuisine japonaise ! Des recettes, des anecdotes, des histoires, des cartes, des gestes, des techniques, des ustensiles, des ingrédients… Une invitation à la découverte des coutumes et des saveurs japonaises !Comment façonner les sushi ? Quelle est la recette traditionnelle de la soupe miso ?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_sumy('resume_cuisine-jap.txt','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
